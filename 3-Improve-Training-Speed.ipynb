{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Training Speed\n",
    "\n",
    "This notebook follows the same basic structure as the previous one, training a pre-trained model on reduced data.\n",
    "\n",
    "We'll make a number of changes designed to make our model training MUCH faster.\n",
    "Since PyTorch gives us so much control, our decisions can greatly increase or decrease training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports for loading data into pytorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# Imports for model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Remember to edit the below paths to the data if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = '/domino/datasets/Serengeti4kImages'\n",
    "#data_root_dir = '/domino/datasets/local/Serengeti4kImages'\n",
    "img_dir = os.path.join(data_root_dir, 'images')\n",
    "metadata_file = os.path.join(data_root_dir, 'reduced_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in metadata and define training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4000 images total\n"
     ]
    }
   ],
   "source": [
    "# Read in metadata and ensure it is shuffled\n",
    "metadata = pd.read_csv(metadata_file).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# Define mappings from label name to index, for \n",
    "category_name_to_id = {\n",
    "    'zebra': 0,\n",
    "    'giraffe': 1,\n",
    "    'wildebeest': 2,\n",
    "    'gazellethomsons': 3\n",
    "}\n",
    "category_id_to_name = {v: k for k,v in category_name_to_id.items()}\n",
    "metadata['category_id'] = metadata['category_name'].apply(lambda x: category_name_to_id[x])\n",
    "print(f\"There are {len(metadata)} images total\")\n",
    "#metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be less than 1000\n",
    "samples_per_class = 100\n",
    "\n",
    "small_metadata = (\n",
    "    metadata\n",
    "    .groupby('category_name')\n",
    "    .apply(pd.DataFrame.sample, n=samples_per_class, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "#small_metadata['category_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = train_test_split(\n",
    "    small_metadata.index,\n",
    "    stratify=small_metadata['category_name'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_metadata = small_metadata.iloc[train_indices].reset_index(drop=True)\n",
    "#print(\"Train counts\")\n",
    "#small_train_metadata['category_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_val_metadata = small_metadata.iloc[val_indices].reset_index(drop=True)\n",
    "#print(\"Val counts\")\n",
    "#small_val_metadata['category_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PyTorch Dataset and DataLoader\n",
    "\n",
    "The `SnapshotSerengetiDataset` class definition is the same as used in the previous notebook.\n",
    "Later in this notebook we'll make some performance improvements!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnapshotSerengetiDataset(Dataset):\n",
    "    def __init__(self, img_metadata, img_dir, transform=None):\n",
    "        # Do some basic validation\n",
    "        required_columns = ['category_id', 'file_name']\n",
    "        if not all([x in img_metadata.columns for x in required_columns]):\n",
    "            raise Exception(f\"img_metadata must be a dataframe including columns {', '.join(required_columns)}\")\n",
    "        if not os.path.isdir(img_dir):\n",
    "            raise Exception(\"img_dir must be a valid directory\")\n",
    "        self.img_metadata = img_metadata\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_metadata)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item_metadata = self.img_metadata.iloc[idx]\n",
    "        image_path = os.path.join(self.img_dir, item_metadata['file_name'])\n",
    "        image = read_image(image_path)\n",
    "        image = torch.mul(image, 1/255.) # scale to [0, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label_idx = item_metadata['category_id']\n",
    "        one_hot_label = (\n",
    "            torch.zeros(len(category_id_to_name), dtype=torch.float)\n",
    "            .scatter_(dim=0, index=torch.tensor(label_idx), value=1)\n",
    "        )\n",
    "        return image, one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These resize and normalize transforms will allow our data to be used with pre-trained networks in later notebooks\n",
    "standard_transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ConvertImageDtype(torch.float32),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SnapshotSerengetiDataset(small_train_metadata, img_dir, transform=standard_transform)\n",
    "val_dataset = SnapshotSerengetiDataset(small_val_metadata, img_dir, transform=standard_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning - using GPUs!\n",
    "\n",
    "The first change we'll make is the addition of GPUs.\n",
    "It's best practice to use a command like the one below instead of hard-coding GPUs, so your code can still run (very slowly!) on a cpu-only machine.\n",
    "Then, just add a command to each of the training functions to move the model and data `to(device)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model():\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(category_id_to_name)) # Rescale fully-connected layer output size\n",
    "    num_frozen_layers = 9\n",
    "\n",
    "    # Freeze `num_frozen_layers`\n",
    "    layer = 0\n",
    "    for child in model.children():\n",
    "        layer += 1\n",
    "        if layer <= num_frozen_layers:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "    print('Number of unfrozen layers: ' + str(layer-num_frozen_layers))\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, quiet=False):\n",
    "    model.train() # Set model to training mode\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, num_correct = [], 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # String formatting choices here are tuned to this small sample\n",
    "        if not quiet:\n",
    "            print(f\"Batch {batch+1}/{num_batches} loss: {loss.item():>7f}  [{(batch+1)*len(X):>3d}/{size:>3d}]\")\n",
    "        train_loss.append(loss.item())\n",
    "        num_correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "    # Return final results for loss and accuracy\n",
    "    avg_train_loss = np.mean(train_loss)\n",
    "    train_accuracy = 100*num_correct/size\n",
    "    print(f\"Train Accuracy: {train_accuracy:>0.1f}%, Avg loss: {avg_train_loss:>8f}\")\n",
    "    return avg_train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, quiet=False):\n",
    "    model.eval() # Set model to evaluate mode\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, num_correct = [], 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            # String formatting choices here are tuned to this small sample\n",
    "            if not quiet:\n",
    "                print(f\"Batch {batch+1}/{num_batches} loss: {loss.item():>7f}  [{(batch+1)*len(X):>3d}/{size:>3d}]\")\n",
    "            test_loss.append(loss.item())\n",
    "            num_correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "    avg_test_loss = np.mean(test_loss)\n",
    "    test_accuracy = 100*num_correct/size\n",
    "    print(f\"Test Accuracy: {test_accuracy:>0.1f}%, Avg loss: {avg_test_loss:>8f}\")\n",
    "    return avg_test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model traing loop on GPUs\n",
    "\n",
    "Let's run the same model training loop as the previous notebook, and see how much GPUs speed things up.\n",
    "(Assuming the same reduced data set, same batch size, same models, we expect the previous notebook loop to have taken about 165 seconds while this cell takes about 55 seconds.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unfrozen layers: 1\n",
      "=====Epoch 1/2=====\n",
      "Train Accuracy: 27.5%, Avg loss: 0.609574\n",
      "Test Accuracy: 40.0%, Avg loss: 0.572357\n",
      "Cumulative time elapsed: 25.9\n",
      "=====Epoch 2/2=====\n",
      "Train Accuracy: 50.9%, Avg loss: 0.562381\n",
      "Test Accuracy: 60.0%, Avg loss: 0.511993\n",
      "Cumulative time elapsed: 50.8\n",
      "-------------------------------\n",
      "Done! Total time elapsed: 50.8s\n"
     ]
    }
   ],
   "source": [
    "model = load_pretrained_model()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=5e-3, momentum=0.9, weight_decay=5e-3)\n",
    "n_epochs = 2\n",
    "learning_curve = pd.DataFrame(index=range(n_epochs), columns=['train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "since = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"=====Epoch {epoch+1}/{n_epochs}=====\")\n",
    "    train_loss, train_acc = train(train_loader, model, loss_fn, optimizer, quiet=True)\n",
    "    val_loss, val_acc = test(val_loader, model, loss_fn, quiet=True)\n",
    "    learning_curve.loc[epoch] = (train_loss, train_acc, val_loss, val_acc)\n",
    "    print(f\"Cumulative time elapsed: {time.time() - since:.1f}\")\n",
    "total_training_time = time.time() - since\n",
    "print(f\"-------------------------------\\nDone! Total time elapsed: {total_training_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling\n",
    "\n",
    "In software development, you don't want to put effort into making something faster unless you know that the part you are working on is the bottleneck.\n",
    "Now that we have made the \"obvious\" improvement of using GPUs, we should do some more digging to find out what part of our code is the slowest.\n",
    "\n",
    "Pytorch has some tools to help with this, but `line_profiler` is a great Jupyter extension to profile functions line-by-line.\n",
    "Let's use it to dig into the train function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need to run this cell if line profiler is not already installed\n",
    "#!pip install line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unfrozen layers: 1\n"
     ]
    }
   ],
   "source": [
    "test_model = load_pretrained_model()\n",
    "optimizer = optim.SGD(test_model.parameters(), lr=5e-3, momentum=0.9, weight_decay=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 29.7%, Avg loss: 0.610899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 20.0166 s\n",
       "File: <ipython-input-14-41fa1fdfc354>\n",
       "Function: train at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def train(dataloader, model, loss_fn, optimizer, quiet=False):\n",
       "     2         1       1711.0   1711.0      0.0      model.train() # Set model to training mode\n",
       "     3         1         19.0     19.0      0.0      size = len(dataloader.dataset)\n",
       "     4         1         18.0     18.0      0.0      num_batches = len(dataloader)\n",
       "     5         1          2.0      2.0      0.0      train_loss, num_correct = [], 0\n",
       "     6         9   19659560.0 2184395.6     98.2      for batch, (X, y) in enumerate(dataloader):\n",
       "     7         8      22781.0   2847.6      0.1          X, y = X.to(device), y.to(device)\n",
       "     8                                                   \n",
       "     9                                                   # Compute prediction error\n",
       "    10         8     214265.0  26783.1      1.1          pred = model(X)\n",
       "    11         8       1967.0    245.9      0.0          loss = loss_fn(pred, y)\n",
       "    12                                           \n",
       "    13                                                   # Backpropagation\n",
       "    14         8       9509.0   1188.6      0.0          optimizer.zero_grad()\n",
       "    15         8       3602.0    450.2      0.0          loss.backward()\n",
       "    16         8      11055.0   1381.9      0.1          optimizer.step()\n",
       "    17                                           \n",
       "    18                                                   # String formatting choices here are tuned to this small sample\n",
       "    19         8         19.0      2.4      0.0          if not quiet:\n",
       "    20                                                       print(f\"Batch {batch+1}/{num_batches} loss: {loss.item():>7f}  [{(batch+1)*len(X):>3d}/{size:>3d}]\")\n",
       "    21         8      90077.0  11259.6      0.5          train_loss.append(loss.item())\n",
       "    22         8       1747.0    218.4      0.0          num_correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
       "    23                                           \n",
       "    24                                               # Return final results for loss and accuracy\n",
       "    25         1        109.0    109.0      0.0      avg_train_loss = np.mean(train_loss)\n",
       "    26         1          3.0      3.0      0.0      train_accuracy = 100*num_correct/size\n",
       "    27         1        170.0    170.0      0.0      print(f\"Train Accuracy: {train_accuracy:>0.1f}%, Avg loss: {avg_train_loss:>8f}\")\n",
       "    28         1          2.0      2.0      0.0      return avg_train_loss, train_accuracy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f train train(train_loader, test_model, loss_fn, optimizer, quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating data load performance\n",
    "\n",
    "From the above profiling, we can see that the vast majority of time is being spent simply loading the data.\n",
    "We can guess that the slowest part of the process will happen somewhere inside the `__get_item__` method of our dataset class, so let's write a benchmarking function to run through those steps separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_bench(idx):\n",
    "    item_metadata = small_train_metadata.iloc[idx]\n",
    "    image_path = os.path.join(img_dir, item_metadata['file_name'])\n",
    "    image = read_image(image_path)\n",
    "    image = torch.mul(image, 1/255.) # scale to [0, 1]\n",
    "    image = standard_transform(image)\n",
    "    label_idx = item_metadata['category_id']\n",
    "    one_hot_label = (torch.zeros(len(category_id_to_name),dtype=torch.float)\n",
    "                     .scatter_(dim=0, index=torch.tensor(label_idx), value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.051844 s\n",
       "File: <ipython-input-21-fec3ed2acf93>\n",
       "Function: get_item_bench at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def get_item_bench(idx):\n",
       "     2         1        566.0    566.0      1.1      item_metadata = small_train_metadata.iloc[idx]\n",
       "     3         1         54.0     54.0      0.1      image_path = os.path.join(img_dir, item_metadata['file_name'])\n",
       "     4         1      30270.0  30270.0     58.4      image = read_image(image_path)\n",
       "     5         1      15577.0  15577.0     30.0      image = torch.mul(image, 1/255.) # scale to [0, 1]\n",
       "     6         1       5237.0   5237.0     10.1      image = standard_transform(image)\n",
       "     7         1         63.0     63.0      0.1      label_idx = item_metadata['category_id']\n",
       "     8         2         52.0     26.0      0.1      one_hot_label = (torch.zeros(len(category_id_to_name),dtype=torch.float)\n",
       "     9         1         25.0     25.0      0.0                       .scatter_(dim=0, index=torch.tensor(label_idx), value=1))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f get_item_bench get_item_bench(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving data load performance\n",
    "\n",
    "About 2/3 of the time is spent on the `read_image` step, and most of the remaining 1/3 is spent on the image transformations.\n",
    "Let's try modifying this function to **cache** transformed images directly in the pytorch tensor format.\n",
    "\n",
    "Run the following benchmark twice to see the performance improvement between the first call (before the image is cached) and the second (after the image is cached).\n",
    "Expect the first call to take about 0.1 seconds total (longer than the original function), while any subsequent call takes less than 0.005 seconds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify path as needed if not running this from a Domino project with a default dataset folder\n",
    "test_cache_dir = f\"/domino/datasets/local/Serengeti4kImages/test_image_cache\"\n",
    "if not os.path.isdir(test_cache_dir):\n",
    "    os.mkdir(test_cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cached_item_bench(idx):\n",
    "    item_metadata = small_train_metadata.iloc[idx]\n",
    "    cache_path = os.path.join(test_cache_dir, item_metadata['file_name'] + '.pt')\n",
    "    image_path = os.path.join(img_dir, item_metadata['file_name'])\n",
    "    if not os.path.isfile(cache_path):    \n",
    "        image = read_image(image_path)\n",
    "        image = torch.mul(image, 1/255.) # scale to [0, 1]\n",
    "        image = standard_transform(image)\n",
    "        torch.save(image, cache_path)\n",
    "    image = torch.load(cache_path)\n",
    "    label_idx = item_metadata['category_id']\n",
    "    one_hot_label = (torch.zeros(len(category_id_to_name), dtype=torch.float)\n",
    "                     .scatter_(dim=0, index=torch.tensor(label_idx), value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.004279 s\n",
       "File: <ipython-input-24-855f6ed6afd8>\n",
       "Function: get_cached_item_bench at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def get_cached_item_bench(idx):\n",
       "     2         1        573.0    573.0     13.4      item_metadata = small_train_metadata.iloc[idx]\n",
       "     3         1         56.0     56.0      1.3      cache_path = os.path.join(test_cache_dir, item_metadata['file_name'] + '.pt')\n",
       "     4         1         21.0     21.0      0.5      image_path = os.path.join(img_dir, item_metadata['file_name'])\n",
       "     5         1        962.0    962.0     22.5      if not os.path.isfile(cache_path):    \n",
       "     6                                                   image = read_image(image_path)\n",
       "     7                                                   image = torch.mul(image, 1/255.) # scale to [0, 1]\n",
       "     8                                                   image = standard_transform(image)\n",
       "     9                                                   torch.save(image, cache_path)\n",
       "    10         1       2540.0   2540.0     59.4      image = torch.load(cache_path)\n",
       "    11         1         40.0     40.0      0.9      label_idx = item_metadata['category_id']\n",
       "    12         2         66.0     33.0      1.5      one_hot_label = (torch.zeros(len(category_id_to_name), dtype=torch.float)\n",
       "    13         1         21.0     21.0      0.5                       .scatter_(dim=0, index=torch.tensor(label_idx), value=1))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f get_cached_item_bench get_cached_item_bench(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redefine SnapshotSerengetiDataset to implement caching\n",
    "\n",
    "The caching improved performance dramatically - with a bit more work the first time an image is read, each time afterwards is ten times as fast!\n",
    "So, let's implement it in a new `FastSnapshotSerengetiDataset` class.\n",
    "\n",
    "#### Some cautions\n",
    "\n",
    "There is a popular quote: \"There are only two hard problems in computer science: cache invalidation and naming things\".\n",
    "\n",
    "Because we're caching the image after performing the transformations, it's critical to keep in mind that this cache will no longer be valid for a different set of transformations!\n",
    "Our new `FastSnapshotSerengetiDataset` class below has no way of \"knowing\" this, so if you use a different set of transformations be sure to do one of the following:\n",
    "* Create a new empty cache folder to pass to `FastSnapshotSerengetiDataset`, OR\n",
    "* Delete the contents of the existing cache folder\n",
    "\n",
    "We've attempted to name the cache folder in a way that will remind us of this, by including our transform variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = f\"/domino/datasets/local/Serengeti4kImages/image_cache_standard_transform\"\n",
    "if not os.path.isdir(cache_dir):\n",
    "    os.mkdir(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastSnapshotSerengetiDataset(Dataset):\n",
    "    def __init__(self, img_metadata, img_dir, cache_dir, transform=None):\n",
    "        # Do some basic validation\n",
    "        if not all([x in img_metadata.columns for x in ['category_id', 'file_name']]):\n",
    "            raise Exception('img_metadata must be a dataframe including columns \"category_name\" and \"file_name\"')\n",
    "        if not os.path.isdir(img_dir):\n",
    "            raise Exception('img_dir must be a valid directory')\n",
    "        if not os.path.isdir(cache_dir):\n",
    "            raise Exception('cache_dir must be a valid directory')\n",
    "        self.img_metadata = img_metadata\n",
    "        self.img_dir = img_dir\n",
    "        self.cache_dir = cache_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_metadata)\n",
    "        \n",
    "    def __cacheitem__(self, image_path, cache_path):\n",
    "        image = read_image(image_path)\n",
    "        image = torch.mul(image, 1/255.) # scale to [0, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        torch.save(image, cache_path)\n",
    "\n",
    "    def __getitem__(self, idx):    \n",
    "        item_metadata = self.img_metadata.iloc[idx]\n",
    "        cache_path = os.path.join(self.cache_dir, item_metadata['file_name'] + '.pt')\n",
    "        if not os.path.isfile(cache_path):\n",
    "            image_path = os.path.join(self.img_dir, item_metadata['file_name'])\n",
    "            self.__cacheitem__(image_path, cache_path)\n",
    "        image = torch.load(cache_path)\n",
    "        label_idx = item_metadata['category_id']\n",
    "        one_hot_label = (\n",
    "            torch.zeros(len(category_id_to_name), dtype=torch.float)\n",
    "            .scatter_(dim=0, index=torch.tensor(label_idx), value=1)\n",
    "        )\n",
    "        return image, one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cached = FastSnapshotSerengetiDataset(small_train_metadata, img_dir, cache_dir, transform=standard_transform)\n",
    "val_dataset_cached = FastSnapshotSerengetiDataset(small_val_metadata, img_dir, cache_dir, transform=standard_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of Dataloaders\n",
    "\n",
    "Pytorch [dataloaders](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) not only make it easier to feed data to a model, but also include a number of features that can be used to improve performance.\n",
    "\n",
    "The are two used here:\n",
    "* `num_workers` tells a dataloader how many parallel processes should run to prep data.\n",
    "* `pin_memory` puts data in page-locked memory, which makes copies of prepared batches to the GPU much faster.\n",
    "\n",
    "Be aware that with too many workers, these options can cause out of memory errors when training.\n",
    "This is an example of a common tradeoff when training neural networks (or any other machine learning algorithms) - holding data in memory is generally more performant than reading repeatedly from disk, but there is a limited amount of memory on any given machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce num_workers if geting memories errors when training below\n",
    "num_workers = 2\n",
    "batch_size = 40\n",
    "train_loader_cached = DataLoader(train_dataset_cached, batch_size=batch_size, num_workers=num_workers, pin_memory=True)\n",
    "val_loader_cached = DataLoader(val_dataset_cached, batch_size=batch_size, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model training loop with caching and GPU\n",
    "\n",
    "Let's try the original model training loop again, with all the performance improvements. Pay particular attention to the time taken by the very first epoch (before any of the images are cached) and the second!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unfrozen layers: 1\n",
      "=====Epoch 1/2=====\n",
      "Train Accuracy: 26.2%, Avg loss: 0.615154\n",
      "Test Accuracy: 37.5%, Avg loss: 0.574257\n",
      "Cumulative time elapsed: 31.4\n",
      "=====Epoch 2/2=====\n",
      "Train Accuracy: 38.1%, Avg loss: 0.568270\n",
      "Test Accuracy: 57.5%, Avg loss: 0.517959\n",
      "Cumulative time elapsed: 32.9\n",
      "-------------------------------\n",
      "Done! Total time elapsed: 32.9s\n"
     ]
    }
   ],
   "source": [
    "model = load_pretrained_model()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=5e-3, momentum=0.9, weight_decay=5e-3)\n",
    "n_epochs = 2\n",
    "learning_curve = pd.DataFrame(index=range(n_epochs), columns=['train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "since = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"=====Epoch {epoch+1}/{n_epochs}=====\")\n",
    "    train_loss, train_acc = train(train_loader_cached, model, loss_fn, optimizer, quiet=True)\n",
    "    val_loss, val_acc = test(val_loader_cached, model, loss_fn, quiet=True)\n",
    "    learning_curve.loc[epoch] = (train_loss, train_acc, val_loss, val_acc)\n",
    "    print(f\"Cumulative time elapsed: {time.time() - since:.1f}\")\n",
    "total_training_time = time.time() - since\n",
    "print(f\"-------------------------------\\nDone! Total time elapsed: {total_training_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train for more epochs\n",
    "\n",
    "Now that the images are cached, we can train for many more epochs in a much shorter time!\n",
    "\n",
    "Notice that we are reloading the model again, but we are NOT resetting the image cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unfrozen layers: 1\n",
      "=====Epoch 1/25=====\n",
      "Train Accuracy: 26.9%, Avg loss: 0.601351\n",
      "Test Accuracy: 31.2%, Avg loss: 0.568748\n",
      "Cumulative time elapsed: 1.1\n",
      "=====Epoch 2/25=====\n",
      "Train Accuracy: 38.1%, Avg loss: 0.563454\n",
      "Test Accuracy: 58.8%, Avg loss: 0.520577\n",
      "Cumulative time elapsed: 2.2\n",
      "=====Epoch 3/25=====\n",
      "Train Accuracy: 61.9%, Avg loss: 0.509818\n",
      "Test Accuracy: 68.8%, Avg loss: 0.485723\n",
      "Cumulative time elapsed: 3.2\n",
      "=====Epoch 4/25=====\n",
      "Train Accuracy: 71.9%, Avg loss: 0.467764\n",
      "Test Accuracy: 70.0%, Avg loss: 0.457666\n",
      "Cumulative time elapsed: 4.3\n",
      "=====Epoch 5/25=====\n",
      "Train Accuracy: 75.0%, Avg loss: 0.437102\n",
      "Test Accuracy: 70.0%, Avg loss: 0.432928\n",
      "Cumulative time elapsed: 5.4\n",
      "=====Epoch 6/25=====\n",
      "Train Accuracy: 78.8%, Avg loss: 0.410016\n",
      "Test Accuracy: 71.2%, Avg loss: 0.412113\n",
      "Cumulative time elapsed: 6.5\n",
      "=====Epoch 7/25=====\n",
      "Train Accuracy: 78.1%, Avg loss: 0.389563\n",
      "Test Accuracy: 71.2%, Avg loss: 0.395715\n",
      "Cumulative time elapsed: 7.6\n",
      "=====Epoch 8/25=====\n",
      "Train Accuracy: 79.1%, Avg loss: 0.371932\n",
      "Test Accuracy: 71.2%, Avg loss: 0.382612\n",
      "Cumulative time elapsed: 8.7\n",
      "=====Epoch 9/25=====\n",
      "Train Accuracy: 80.0%, Avg loss: 0.357231\n",
      "Test Accuracy: 71.2%, Avg loss: 0.371818\n",
      "Cumulative time elapsed: 9.8\n",
      "=====Epoch 10/25=====\n",
      "Train Accuracy: 80.0%, Avg loss: 0.344931\n",
      "Test Accuracy: 71.2%, Avg loss: 0.362497\n",
      "Cumulative time elapsed: 10.9\n",
      "=====Epoch 11/25=====\n",
      "Train Accuracy: 81.2%, Avg loss: 0.333968\n",
      "Test Accuracy: 71.2%, Avg loss: 0.354789\n",
      "Cumulative time elapsed: 12.0\n",
      "=====Epoch 12/25=====\n",
      "Train Accuracy: 82.5%, Avg loss: 0.324510\n",
      "Test Accuracy: 71.2%, Avg loss: 0.348070\n",
      "Cumulative time elapsed: 13.1\n",
      "=====Epoch 13/25=====\n",
      "Train Accuracy: 83.1%, Avg loss: 0.316000\n",
      "Test Accuracy: 71.2%, Avg loss: 0.342237\n",
      "Cumulative time elapsed: 14.2\n",
      "=====Epoch 14/25=====\n",
      "Train Accuracy: 84.1%, Avg loss: 0.308329\n",
      "Test Accuracy: 71.2%, Avg loss: 0.337206\n",
      "Cumulative time elapsed: 15.3\n",
      "=====Epoch 15/25=====\n",
      "Train Accuracy: 83.8%, Avg loss: 0.301416\n",
      "Test Accuracy: 71.2%, Avg loss: 0.332705\n",
      "Cumulative time elapsed: 16.3\n",
      "=====Epoch 16/25=====\n",
      "Train Accuracy: 84.1%, Avg loss: 0.295046\n",
      "Test Accuracy: 72.5%, Avg loss: 0.328748\n",
      "Cumulative time elapsed: 17.4\n",
      "=====Epoch 17/25=====\n",
      "Train Accuracy: 84.4%, Avg loss: 0.289199\n",
      "Test Accuracy: 72.5%, Avg loss: 0.325233\n",
      "Cumulative time elapsed: 18.5\n",
      "=====Epoch 18/25=====\n",
      "Train Accuracy: 85.0%, Avg loss: 0.283792\n",
      "Test Accuracy: 72.5%, Avg loss: 0.322064\n",
      "Cumulative time elapsed: 19.6\n",
      "=====Epoch 19/25=====\n",
      "Train Accuracy: 85.6%, Avg loss: 0.278747\n",
      "Test Accuracy: 72.5%, Avg loss: 0.319232\n",
      "Cumulative time elapsed: 20.7\n",
      "=====Epoch 20/25=====\n",
      "Train Accuracy: 85.3%, Avg loss: 0.274041\n",
      "Test Accuracy: 73.8%, Avg loss: 0.316678\n",
      "Cumulative time elapsed: 21.8\n",
      "=====Epoch 21/25=====\n",
      "Train Accuracy: 85.3%, Avg loss: 0.269625\n",
      "Test Accuracy: 73.8%, Avg loss: 0.314362\n",
      "Cumulative time elapsed: 22.9\n",
      "=====Epoch 22/25=====\n",
      "Train Accuracy: 85.6%, Avg loss: 0.265464\n",
      "Test Accuracy: 73.8%, Avg loss: 0.312267\n",
      "Cumulative time elapsed: 24.0\n",
      "=====Epoch 23/25=====\n",
      "Train Accuracy: 85.9%, Avg loss: 0.261538\n",
      "Test Accuracy: 73.8%, Avg loss: 0.310361\n",
      "Cumulative time elapsed: 25.0\n",
      "=====Epoch 24/25=====\n",
      "Train Accuracy: 85.9%, Avg loss: 0.257819\n",
      "Test Accuracy: 73.8%, Avg loss: 0.308623\n",
      "Cumulative time elapsed: 26.1\n",
      "=====Epoch 25/25=====\n",
      "Train Accuracy: 85.9%, Avg loss: 0.254287\n",
      "Test Accuracy: 73.8%, Avg loss: 0.307038\n",
      "Cumulative time elapsed: 27.1\n",
      "-------------------------------\n",
      "Done! Total time elapsed: 27.1s\n"
     ]
    }
   ],
   "source": [
    "model = load_pretrained_model()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=5e-3, momentum=0.9, weight_decay=5e-3)\n",
    "n_epochs = 25\n",
    "learning_curve = pd.DataFrame(index=range(n_epochs), columns=['train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "since = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"=====Epoch {epoch+1}/{n_epochs}=====\")\n",
    "    train_loss, train_acc = train(train_loader_cached, model, loss_fn, optimizer, quiet=True)\n",
    "    val_loss, val_acc = test(val_loader_cached, model, loss_fn, quiet=True)\n",
    "    learning_curve.loc[epoch] = (train_loss, train_acc, val_loss, val_acc)\n",
    "    print(f\"Cumulative time elapsed: {time.time() - since:.1f}\")\n",
    "total_training_time = time.time() - since\n",
    "print(f\"-------------------------------\\nDone! Total time elapsed: {total_training_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(learning_curve):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6.4, 7))\n",
    "    x = learning_curve.index + 1\n",
    "    ax1.plot(x, learning_curve['train_acc'], label = 'training')\n",
    "    ax1.plot(x, learning_curve['val_acc'], label = 'validation')\n",
    "    ax1.axhline(100/len(category_name_to_id), label = 'random', c='r', ls=':')\n",
    "    ax1.axhline(100, label = 'perfect', c='g', ls=':')\n",
    "    ax1.legend()\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax2.plot(x, learning_curve['train_loss'], label = 'training')\n",
    "    ax2.plot(x, learning_curve['val_loss'], label = 'validation')\n",
    "    ax2.legend()\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 460.8x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(learning_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Utilization\n",
    "\n",
    "While a model is training, you may want to confirm that's it's making full use of your hardware. If it isn't, that's a sign that you can do things like train larger batches, a larger model, or do more things in parallel.\n",
    "\n",
    "`nvidia-smi` shows information about the GPUs in your system and their memory/processor usage.\n",
    "\n",
    "`top` is a commonly-used linux command showing the most active processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 23 17:15:24 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   35C    P0    38W / 300W |   2033MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\u001b[H\u001b[2J\u001b[mtop - 17:15:28 up 26 min,  0 users,  load average: 2.37, 1.67, 1.58\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m  11 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   1 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m  10 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  0.8 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  0.8 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 98.3 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "MiB Mem :\u001b[m\u001b[m\u001b[1m  61287.0 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m  19621.6 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m   4302.5 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m  37362.9 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "MiB Swap:\u001b[m\u001b[m\u001b[1m      0.0 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m      0.0 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m      0.0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m  56305.8 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\u001b[7m    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m      1 root      20   0    8844   3656   3280 S   0.0   0.0   0:00.10 runLaun+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    277 ubuntu    20   0    8844   3932   3528 S   0.0   0.0   0:00.01 command+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    331 ubuntu    20   0    7120   3580   3232 S   0.0   0.0   0:00.00 start    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    334 ubuntu    20   0    8844   1768   1364 S   0.0   0.0   0:00.00 command+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    335 ubuntu    20   0    8844   1768   1364 S   0.0   0.0   0:00.00 command+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    336 ubuntu    20   0    5508    540    464 S   0.0   0.0   0:00.00 tee      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    339 ubuntu    20   0    5508    536    456 S   0.0   0.0   0:00.00 tee      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    360 ubuntu    20   0  691752 125544  26992 S   0.0   0.2   0:07.83 jupyter+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    447 ubuntu    20   0   15.0g   3.7g   1.3g S   0.0   6.2   2:56.67 python   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   1021 ubuntu    20   0    2632    560    476 S   0.0   0.0   0:00.60 dash     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m   1022 ubuntu    20   0    9132   3808   3292 R   0.0   0.0   0:00.00 top      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[J\u001b[?1l\u001b>\u001b[25;1H\n",
      "\u001b[K"
     ]
    }
   ],
   "source": [
    "!top -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "You may occasionally need to run the following command to clear cached data from the GPU between model trainings.\n",
    "\n",
    "This does not affect our cache of pretransformed images, since those were saved to disk.\n",
    "\n",
    "If you see high memory usage in the `nvidia-smi` output above you can try running it and then running `nvidia-smi` again to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
